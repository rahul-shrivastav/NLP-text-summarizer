{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c190175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, InputLayer, TimeDistributed\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split    \n",
    "\n",
    "import string, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3784e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"./dataset/news_summary.csv\", encoding='iso-8859-1')\n",
    "raw = pd.read_csv(\"./dataset/news_summary_more.csv\", encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "911636ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'min_text_len':40,\n",
    "          'max_text_len':60,\n",
    "          'max_summary_len':30,\n",
    "          'latent_dim' : 300,\n",
    "          'embedding_dim' : 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([raw, summary]).reset_index(drop=True)\n",
    "\n",
    "print(f'Before filtering: {df.shape}')\n",
    "df = df.loc[((df['text'].str.split(\" \").str.len()>config['min_text_len']) & (df['text'].str.split(\" \").str.len()<config['max_text_len']))].reset_index(drop=True)\n",
    "print(f'After filtering: {df.shape}')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82c0127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_strip(sentence):\n",
    "\n",
    "  sentence = re.sub(\"(\\\\t)\", \" \", str(sentence)).lower()\n",
    "  sentence = re.sub(\"(\\\\r)\", \" \", str(sentence)).lower()\n",
    "  sentence = re.sub(\"(\\\\n)\", \" \", str(sentence)).lower()\n",
    "\n",
    "  sentence = re.sub(\"(--+)\", \" \", str(sentence)).lower()\n",
    "\n",
    "  sentence = re.sub(\"(\\.\\.+)\", \" \", str(sentence)).lower()\n",
    "\n",
    "  sentence = re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", \" \", str(sentence)).lower()\n",
    "  sentence = re.sub(r\"(\\\\x9\\d)\", \" \", str(sentence)).lower()\n",
    "\n",
    "  sentence = re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", \"CM_NUM\", str(sentence)).lower()\n",
    "  sentence = re.sub(\"(\\.\\s+)\", \" \", str(sentence)).lower()\n",
    "  sentence = re.sub(\"(\\-\\s+)\", \" \", str(sentence)).lower()\n",
    "  sentence = re.sub(\"(\\:\\s+)\", \" \", str(sentence)).lower()\n",
    "  sentence = re.sub(\"(\\s+)\", \" \", str(sentence)).lower()\n",
    "  \n",
    "  return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "11a24442",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df.text.apply(lambda x: text_strip(x))\n",
    "df['cleaned_headlines'] = df.headlines.apply(lambda x: '_START_ '+ text_strip(x) + ' _END_')\n",
    "df['cleaned_headlines'] = df['cleaned_headlines'].apply(lambda x: 'sostok ' + x + ' eostok')\n",
    "\n",
    "df = df[((df.cleaned_text.str.split().str.len()<=config['max_text_len']) & (df.cleaned_headlines.str.split().str.len()<=(config['max_summary_len']+4)))].copy()\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df = df.drop(['text', 'headlines'], axis=1)\n",
    "df = df.rename(columns = {'cleaned_text':'text', 'cleaned_headlines':'summary'})\n",
    "                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df['text']\n",
    "Y = df['summary']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rare_words(text_col):\n",
    "\n",
    "  text_tokenizer = Tokenizer()    \n",
    "  text_tokenizer.fit_on_texts(list(text_col))\n",
    "\n",
    "  thresh = 5\n",
    "\n",
    "  cnt = 0\n",
    "  tot_cnt = 0\n",
    "\n",
    "  for key, value in text_tokenizer.word_counts.items():\n",
    "      tot_cnt = tot_cnt + 1\n",
    "      if value < thresh:\n",
    "          cnt = cnt + 1\n",
    "\n",
    "  print(\"% of rare words in vocabulary:\",(cnt / tot_cnt) * 100)\n",
    "  \n",
    "  return cnt, tot_cnt\n",
    "\n",
    "x_train_cnt, x_train_tot_cnt = get_rare_words(text_col=x_train)\n",
    "y_train_cnt, y_train_tot_cnt = get_rare_words(text_col=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae223919",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer(num_words=x_train_tot_cnt - x_train_cnt) \n",
    "\n",
    "x_tokenizer.fit_on_texts(list(x_train))\n",
    "\n",
    "x_tr_seq = x_tokenizer.texts_to_sequences(x_train) \n",
    "x_val_seq = x_tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_tr = pad_sequences(x_tr_seq,  maxlen=config['max_text_len'], padding='post')\n",
    "x_val = pad_sequences(x_val_seq, maxlen=config['max_text_len'], padding='post')\n",
    "\n",
    "x_voc = x_tokenizer.num_words + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8ca7df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer(num_words=y_train_tot_cnt - y_train_cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "y_tr_seq = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_val_seq = y_tokenizer.texts_to_sequences(y_test) \n",
    "\n",
    "y_tr = pad_sequences(y_tr_seq, maxlen=config['max_summary_len'], padding='post')\n",
    "y_val = pad_sequences(y_val_seq, maxlen=config['max_summary_len'], padding='post')\n",
    "\n",
    "y_voc = y_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e9331365",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'min_text_len':40,\n",
    "          'max_text_len':60,\n",
    "          'max_summary_len':30,\n",
    "          'latent_dim' : 300,\n",
    "          'embedding_dim' : 200}\n",
    "\n",
    "\n",
    "latent_dim = config['latent_dim']\n",
    "embedding_dim = config['embedding_dim']\n",
    "max_text_len = config['max_text_len']\n",
    "max_summary_len = config['max_summary_len']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f02057c",
   "metadata": {},
   "source": [
    "ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e84893e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_inputs = Input(shape=(max_text_len, ))\n",
    "\n",
    "enc_emb = Embedding(input_dim = x_voc, output_dim = embedding_dim, trainable=True)(encoder_inputs)\n",
    "\n",
    "encoder_lstm1 = LSTM(units = latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True,\n",
    "                     return_state=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "encoder_lstm3 = LSTM(latent_dim, return_state=True,\n",
    "                     return_sequences=True, dropout=0.4,\n",
    "                     recurrent_dropout=0.4)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286aefdb",
   "metadata": {},
   "source": [
    "DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16d265e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, )) \n",
    "\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim, trainable=True)  \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True,\n",
    "                    return_state=True, dropout=0.4,\n",
    "                    recurrent_dropout=0.2)\n",
    "\n",
    "(decoder_outputs, decoder_fwd_state, decoder_back_state) = decoder_lstm(dec_emb, initial_state=[state_h, state_c]) \n",
    "\n",
    "decoder_dense = TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c5c738f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,206,600</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,745,200</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), │    <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">601,200</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,626,526</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8726</span>)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m200\u001b[0m)   │  \u001b[38;5;34m4,206,600\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m300\u001b[0m), │    \u001b[38;5;34m601,200\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m300\u001b[0m), │    \u001b[38;5;34m721,200\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m) │  \u001b[38;5;34m1,745,200\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m300\u001b[0m), │    \u001b[38;5;34m721,200\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m601,200\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m300\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │  \u001b[38;5;34m2,626,526\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m8726\u001b[0m)             │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,223,126</span> (42.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,223,126\u001b[0m (42.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,223,126</span> (42.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,223,126\u001b[0m (42.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25575223",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_name = \"model.weights.h5\"\n",
    "\n",
    "save_model = tf.keras.callbacks.ModelCheckpoint(filepath=model_name,\n",
    "                                                save_weights_only=True,\n",
    "                                                save_best_only=True,\n",
    "                                                verbose=1)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "history = model.fit(\n",
    "    [x_tr, y_tr[:, :-1]],\n",
    "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
    "    epochs=70,\n",
    "    callbacks=[es, save_model],\n",
    "    batch_size=1024,\n",
    "    validation_data=([x_val, y_val[:, :-1]],\n",
    "                     y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]),\n",
    "    )\n",
    "\n",
    "model.load_weights('./model.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2cf0fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,\n",
    "                      state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "(decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,\n",
    "        initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,\n",
    "                      decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "89b0d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    " \n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq, verbose=0)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    target_seq[0, 0] = target_word_index['sostok'] \n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = '' \n",
    "\n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
    "                + [e_out, e_h, e_c], verbose=0)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != 'eostok':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        if sampled_token == 'eostok' or len(decoded_sentence.split()) \\\n",
    "            >= max_summary_len - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        (e_h, e_c) = (h, c)\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4af1a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8643f65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2text(input_seq):\n",
    "\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0: \n",
    "            newString = newString + reverse_source_word_index[i] + ' '\n",
    "\n",
    "    return newString\n",
    "\n",
    "def seq2summary(input_seq):\n",
    "\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if (i != 0) and (i != target_word_index['sostok']) and (i != target_word_index['eostok']):\n",
    "            newString = newString + reverse_target_word_index[i] + ' '\n",
    "\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: a man has been caught taking videos of girls at the school arts festival organised in kerala s thrissur by cutting a hole into his slipper and fitting a phone camera in it the police who arrested the accused after noticing his suspicious movements said that he went through the crowds trying to take photos of women from below \n",
      "Original summary: start kerala man caught taking videos on camera end \n",
      "Predicted summary:  start man who stole up to remove hiv at delhi metro end\n",
      "\n",
      "Review: the cbi on friday arrested the key accused in the 24 year old rss madras headquarters bomb blast from the outskirts of chennai the prime accused in the case mushtaq ahmed was absconding since the 1993 blast that claimed 11 lives ahmed had allegedly procured the explosive material for assembling the bomb and provided shelter to other accused persons \n",
      "Original summary: start cbi arrests prime accused in rss madras headquarters blast end \n",
      "Predicted summary:  start cbi arrests ex j k police officer for murder in j k end\n",
      "\n",
      "Review: actor anil kapoor has said that amitabh bachchan who took a five year long break after his 1992 film had advised him never to commit the mistake of taking a break from films anil said i went back and immediately signed two new films i have never taken a break in my 38 year long career \n",
      "Original summary: start told me never to take a break from films anil end \n",
      "Predicted summary:  start i was a single in my film with karan johar on b day end\n",
      "\n",
      "Review: at least 40 militants were killed on saturday after a us air strike targeted an isis camp in afghanistan s nangarhar province the camp was used to train isis suicide bombers according to reports several weapons ammunition and explosives belonging to the terror group were also destroyed in the air strike officials said \n",
      "Original summary: start 40 killed in us air strike on afghan isis training camp end \n",
      "Predicted summary:  start isis kills civilians in afghanistan end\n",
      "\n",
      "Review: the trailer of upcoming psychological horror thriller film mother starring oscar winning actress jennifer lawrence has been released it will compete at this year s venice film festival the film has been directed by darren who is known for directing the oscar nominated movie black swan also starring javier and michelle mother will release on september 15 \n",
      "Original summary: start trailer of jennifer lawrence starrer mother released end \n",
      "Predicted summary:  start trailer of kalki koechlin starrer released end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual = []\n",
    "predicted = []\n",
    "for i in range(0, 50):\n",
    "    print ('Review:', seq2text(x_tr[i]))\n",
    "    \n",
    "    actual.append(seq2summary(y_tr[i]))\n",
    "    print ('Original summary:', actual[-1])\n",
    "    \n",
    "    predicted.append(decode_sequence(x_tr[i].reshape(1, config['max_text_len'])))\n",
    "    print ('Predicted summary:', predicted[-1])\n",
    "    print()\n",
    "prediction_df = pd.DataFrame({'Actual':actual, 'Predicted':predicted})\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
